---
title: "Assignment V"
author: "Troy Zhongyi Zhang"
date: "March 5, 2019"
output: html_document
---

### Due Date: Monday March 11, 2019 at 5:59 pm.

## Introduction
We are going to use a simulated two-class data set with 200 observations for training and 100 observations for testing, which includes two features, and in which there is a visible but non-linear separation between the two classes. Use the code below for creating such a dataset.

```{r, echo=TRUE}
rm(list = ls())
library(plyr)
library(dplyr)
library(pROC)
library(caret)


# set a seed
set.seed(1)

# ---- Create a training set ---- #
# create a matrix with 200 rows and two colums with values sampled from a normal distribution.
x <- matrix(rnorm(200*2), ncol = 2)
# Introduce some non-linearity where we move points around
x[1:100,] <- x[1:100,] + 2
x[101:150,] <- x[101:150,] -2
# assign class labels
y <- c(rep(1, 150), rep(0, 50))
# this forms a training set
d.train <- data.frame(x = x, y = as.factor(y))
names(d.train) <- c("X1", "X2", "Y")


# ---- Create a test set ---- #
# create a matrix with 100 rows and two colums with values sampled from a normal distribution.
x <- matrix(rnorm(100*2), ncol = 2)
# Introduce some non-linearity where we move points around
x[1:25,] <- x[1:25,] + 2 # moves points to the top-right of a 2D space
x[26:75,] <- x[26:75,] -2 # moves points to the bottom-left of a 2D space
# assign class labels
y <- c(rep(1, 75), rep(0, 25)) 
# this forms a testing set
d.test <- data.frame(x = x, y = as.factor(y))
names(d.test) <- c("X1", "X2", "Y")
```




## Question 1
Create a scatter-plot of all data points in the training set color-labeled by their class type. You will notice that one class is in the center of all points of the other class. In other words, the separation between the classes is a circle around the points with Y as -1. Repeat the same for the testing set. 

```{r}
# Insert your code below


#plot(d.train$X2,d.train$X1,data = d.train,main="X1 vs. X2",xlab="X1", ylab="X2",type="p", col="blue", pch=19, cex=1)

g1 <- ggplot(d.train, aes(x=X1, y=X2, color = Y)) + geom_point()
plot(g1)

g2 <- ggplot(d.test, aes(x=X1, y=X2, color = Y)) + geom_point()
plot(g2)

```



## Question 2
Buid a neural network with a variable hidden layer network size from 2 to 50. Feel free to explore different decay rates using "expand.grid" as shown in class. Perform testing on d.test and report the final AUC with 95% CI. 

```{r}
# Insert your code below
library(nnet)

d.train <- d.train %>%
   mutate(Y = as.factor(Y))

d.test <- d.test %>%
   mutate(Y = as.factor(Y))

d.train$Y_cat <- ifelse(d.train$Y == 1, "Yes", "No")
d.train2 <- d.train %>% select(-c(Y))

d.test$Y_cat <- ifelse(d.test$Y == 1, "Yes", "No")
d.test2 <- d.test %>% select(-c(Y))

fit_control <- trainControl(method = "cv", number = 3, classProbs = TRUE, summaryFunction = twoClassSummary)

nnet_params1 <- expand.grid(size = seq(from = 2, to = 50, by = 1),
decay = 3e-4)
head(nnet_params1)

nnet_params2 <- expand.grid(size = seq(from = 2, to = 50, by = 1),
decay = 4e-4)
head(nnet_params2)

nnet_params3 <- expand.grid(size = seq(from = 2, to = 50, by = 1),
decay = 5e-4)
head(nnet_params3)

#m.ann0 <- train(Y_cat ~ ., data = d.train2, method = "nnet", metric = "ROC", trControl = fit_control, tuneGrid = nnet_params1, trace = FALSE)
#print((m.ann0))
#print(summary(m.ann0$finalModel))

#m.ann1 <- train(Y_cat ~ ., data = d.train2, method = "nnet", metric = "ROC", trControl = fit_control, tuneGrid = nnet_params2, trace = FALSE)
#print((m.ann1))
#print(summary(m.ann1$finalModel))

m.ann <- train(Y_cat ~ ., data = d.train2, method = "nnet", metric = "ROC", trControl = fit_control, tuneGrid = nnet_params3, trace = FALSE)

print((m.ann))

print(summary(m.ann$finalModel))

test_predictions <- predict(m.ann, newdata = d.test2, type = "prob")
head(test_predictions)

d.test$predict_Y<- test_predictions$Yes

pred_roc <- roc(response=d.test2$Y_cat, predictor = d.test$predict_Y, direction = "<")
paste("AUC :", auc(pred_roc))

ci_auc_perf0 <- ci.auc(pred_roc)
cat("95% CI: ", ci_auc_perf0, "\n")


```



## Question 3

1. Build a logistic regression prediction model using d.train. Test on d.test, and report your test AUC.


```{r}
# Insert your code below

library(nnet)


# set a seed
set.seed(1)

# ---- Create a training set ---- #
# create a matrix with 200 rows and two colums with values sampled from a normal distribution.
x <- matrix(rnorm(200*2), ncol = 2)
# Introduce some non-linearity where we move points around
x[1:100,] <- x[1:100,] + 2
x[101:150,] <- x[101:150,] -2
# assign class labels
y <- c(rep(1, 150), rep(0, 50))
# this forms a training set
d.train <- data.frame(x = x, y = as.factor(y))
names(d.train) <- c("X1", "X2", "Y")


# ---- Create a test set ---- #
# create a matrix with 100 rows and two colums with values sampled from a normal distribution.
x <- matrix(rnorm(100*2), ncol = 2)
# Introduce some non-linearity where we move points around
x[1:25,] <- x[1:25,] + 2 # moves points to the top-right of a 2D space
x[26:75,] <- x[26:75,] -2 # moves points to the bottom-left of a 2D space
# assign class labels
y <- c(rep(1, 75), rep(0, 25)) 
# this forms a testing set
d.test <- data.frame(x = x, y = as.factor(y))
names(d.test) <- c("X1", "X2", "Y")

#Start from here:
d.train <- d.train %>%
   mutate(Y = as.factor(Y))

d.test <- d.test %>%
   mutate(Y = as.factor(Y))

m.log <- glm(Y ~ ., family = "binomial", data = d.train)

d.test$pred_Y <- predict.glm(m.log, newdata = d.test, type = "response")

pred <- roc(response = d.test$Y, predictor = d.test$pred_Y, direction = "<")

auc_perf <- auc(pred)
cat("AUC: ", auc_perf, "\n")

# Get 95% CI
ci_auc_perf <- ci.auc(pred)
cat("95% CI: ", ci_auc_perf, "\n")


```




2. Which of the two models leads to better performance? Explain in no more than 2 sentences why.        

Ans. The neural network model leads to better performance since it has a larger AUC (Area Under Curve) than the logistic regression prediction model. The AUC for the neural network model is 0.949 (AUC>=0.8 indicates great classification), which is larger than 0.339, the AUC of the logistic regression prediction model.